#!/usr/bin/env python3
"""
ETH Exposure Data Fetcher - Port2 Integration

This script uses the proven live scraper (99.98% accuracy) to fetch comprehensive
ETH exposure data and save it to JSON format for offline analysis in Port2.

Features:
- Uses working live scraper with <$10 difference validation
- Exports detailed token breakdown (219+ tokens)
- Exports protocol breakdown (39+ protocols)
- Saves data in Port2-compatible JSON format
- Includes validation and summary statistics
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple

# Add scrapers to path
sys.path.append(os.path.join(os.path.dirname(__file__), "scrapers"))

try:
    from enhanced_debank_scraper import EnhancedDeBankScraper
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Please ensure enhanced_debank_scraper.py is in the scrapers directory")
    sys.exit(1)


class ETHExposureDataFetcher:
    """Fetches comprehensive ETH exposure data using proven live scraper."""

    def __init__(self, output_dir: str = "exported_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.scraper = EnhancedDeBankScraper()

    async def fetch_and_export_address(self, address: str, export_name: Optional[str] = None):
        """Fetch comprehensive data for an address and export to JSON."""
        print(f"üöÄ Fetching comprehensive ETH exposure data for {address[:8]}...")

        # Use the proven live scraper
        try:
            wallet_data = await self.scraper.scrape_wallet_enhanced(address)

            if not wallet_data:
                print(f"‚ùå No data returned for address {address}")
                return None, None

            # Convert wallet_data to tokens, protocols, summary_stats format
            tokens = [
                {
                    "symbol": token.symbol,
                    "amount": token.amount,
                    "value_usd": token.usd_value,
                    "category": token.category,
                    "chain": token.chain,
                    "source": token.source,
                }
                for token in wallet_data.tokens
            ]

            protocols = []
            for proto in wallet_data.protocols:
                proto_copy = json.loads(json.dumps(proto)) if isinstance(proto, dict) else proto
                if (
                    isinstance(proto_copy, dict)
                    and str(proto_copy.get("name", "")).lower() == "polymarket"
                ):
                    for position in proto_copy.get("positions", []) or []:
                        if (
                            isinstance(position, dict)
                            and str(position.get("header_type", "")).lower() == "name"
                        ):
                            outcome_value = position.get("asset") or position.get("label")
                            if outcome_value:
                                position["side"] = outcome_value
                            position["asset"] = "Polymarket Position"
                protocols.append(proto_copy)

            summary_stats = {
                "portfolio_value_usd": wallet_data.total_usd_value,
                "total_value_usd": sum(token.usd_value for token in wallet_data.tokens)
                + sum(
                    p.get("total_value", 0)
                    for p in protocols
                    if not (
                        p.get("name") == "Wallet"
                        and p.get("chain") == "unknown"
                        and p.get("source") == "reverted_simple_parsing"
                    )
                ),
                "total_tokens": len(tokens),
                "total_protocols": len(
                    [
                        p
                        for p in protocols
                        if not (
                            p.get("name") == "Wallet"
                            and p.get("chain") == "unknown"
                            and p.get("source") == "reverted_simple_parsing"
                        )
                    ]
                ),
            }

            # Create comprehensive export data
            export_data = self._create_export_data(address, tokens, protocols, summary_stats)

            # Save to JSON
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = (
                export_name if export_name else f"eth_exposure_{address[:8]}_{timestamp}.json"
            )
            filepath = self.output_dir / filename

            with open(filepath, "w") as f:
                json.dump(export_data, f, indent=2, default=str)

            print(f"üíæ Data exported to: {filepath}")
            print(
                f"üìà Summary: {len(tokens)} tokens, {len(protocols)} protocols, ${summary_stats['total_value_usd']:,.2f} total"
            )

            return export_data, filepath

        except Exception as e:
            print(f"‚ùå Error fetching data for {address}: {e}")
            return None, None

    def _create_export_data(self, address: str, tokens: list, protocols: list, summary_stats: dict):
        """Create export data in the exact same raw format as enhanced_debank_scraper.py saves."""

        # Convert tokens to the exact format the enhanced debank scraper uses
        raw_tokens = []
        for token in tokens:
            raw_tokens.append(
                {
                    "symbol": token.get("symbol", "UNKNOWN"),
                    "amount": token.get("amount", 0),
                    "usd_value": token.get("value_usd", 0),
                    "category": token.get("category", "other_crypto"),
                    "chain": token.get("chain", "ethereum"),  # Add chain field with default
                }
            )

        # Enhanced filter for fallback 'Wallet' protocols to prevent double counting
        filtered_protocols = []
        for protocol in protocols:
            # Primary filter: Known problematic fallback protocols
            if (
                protocol.get("name") == "Wallet"
                and protocol.get("chain") == "unknown"
                and protocol.get("source") == "reverted_simple_parsing"
            ):
                print(
                    f"üö´ Filtering out fallback 'Wallet' protocol (${protocol.get('total_value', 0):,.0f}) to prevent double counting"
                )
                continue

            # Additional safeguard: Flag protocols explicitly marked as risky
            if protocol.get("risk_double_count", False):
                print(
                    f"üö´ Filtering out high-risk protocol '{protocol.get('name')}' (${protocol.get('total_value', 0):,.0f}) to prevent double counting"
                )
                continue

            # Additional safeguard: Check for suspiciously generic protocols with exact wallet total match
            if (
                protocol.get("name") in ["Wallet", "Portfolio", "Total", "Balance"]
                and protocol.get("total_value", 0) > 0
            ):
                # This would need the wallet total to compare, but serves as documentation
                print(
                    f"‚ö†Ô∏è Generic protocol name detected: '{protocol.get('name')}' - verify not duplicate"
                )

            filtered_protocols.append(protocol)

        # Return the EXACT same format as enhanced_debank_scraper.py save_results method
        # WITHOUT exposure_breakdown to keep it purely raw data
        export_data = {
            "address": address,
            "total_usd_value": summary_stats.get("portfolio_value_usd", 0),
            "timestamp": datetime.now().isoformat(),
            "tokens": raw_tokens,
            "protocols": filtered_protocols,  # Use filtered protocols
        }

        return export_data

    def _filter_eth_tokens(self, tokens: list):
        """Filter tokens that are ETH-related."""
        eth_related_symbols = {
            "ETH",
            "WETH",
            "stETH",
            "rETH",
            "cbETH",
            "sETH2",
            "ankrETH",
            "BETH",
            "swETH",
            "frxETH",
            "sfrxETH",
            "osETH",
            "wstETH",
        }

        eth_tokens = []
        for token in tokens:
            symbol = token.get("symbol", "").upper()
            if symbol in eth_related_symbols:
                eth_tokens.append(token)

        return eth_tokens

    def _filter_eth_protocols(self, protocols: list):
        """Filter protocols that likely contain ETH exposure."""
        # Most DeFi protocols contain ETH exposure
        return protocols  # For now, include all protocols

    def _create_token_breakdown(self, eth_tokens: list):
        """Create detailed token breakdown for Port2 analysis."""
        breakdown = {}
        for token in eth_tokens:
            symbol = token.get("symbol", "UNKNOWN")
            breakdown[symbol] = {
                "amount": token.get("amount", 0),
                "value_usd": token.get("value_usd", 0),
                "percentage_of_eth_exposure": 0,  # Will be calculated later
            }

        # Calculate percentages
        total_eth_value = sum(token["value_usd"] for token in breakdown.values())
        if total_eth_value > 0:
            for token_data in breakdown.values():
                token_data["percentage_of_eth_exposure"] = (
                    token_data["value_usd"] / total_eth_value
                ) * 100

        return breakdown

    def _create_protocol_breakdown(self, eth_protocols: list):
        """Create detailed protocol breakdown for Port2 analysis."""
        breakdown = {}
        for protocol in eth_protocols:
            name = protocol.get("name", "UNKNOWN")
            breakdown[name] = {
                "total_usd": protocol.get("total_usd", 0),
                "percentage_of_protocol_exposure": 0,  # Will be calculated later
            }

        # Calculate percentages
        total_protocol_value = sum(protocol["total_usd"] for protocol in breakdown.values())
        if total_protocol_value > 0:
            for protocol_data in breakdown.values():
                protocol_data["percentage_of_protocol_exposure"] = (
                    protocol_data["total_usd"] / total_protocol_value
                ) * 100

        return breakdown

    def _is_stablecoin(self, symbol: str) -> bool:
        """Check if a token symbol is a stablecoin."""
        stablecoins = {
            "USDT",
            "USDC",
            "BUSD",
            "DAI",
            "FRAX",
            "TUSD",
            "USDP",
            "GUSD",
            "LUSD",
            "MIM",
            "UST",
            "USDN",
            "FEI",
            "TRIBE",
            "USDD",
            "USTC",
        }
        return symbol.upper() in stablecoins

    def _is_major_crypto(self, symbol: str) -> bool:
        """Check if a token symbol is a major cryptocurrency."""
        major_cryptos = {
            "BTC",
            "ETH",
            "WETH",
            "BNB",
            "SOL",
            "ADA",
            "AVAX",
            "DOT",
            "MATIC",
            "LINK",
            "UNI",
            "LTC",
            "XRP",
            "DOGE",
            "SHIB",
            "ATOM",
            "NEAR",
            "APT",
        }
        return symbol.upper() in major_cryptos

    def _is_defi_token(self, symbol: str) -> bool:
        """Check if a token symbol is a DeFi token."""
        defi_tokens = {
            "AAVE",
            "COMP",
            "MKR",
            "SNX",
            "CRV",
            "BAL",
            "YFI",
            "SUSHI",
            "1INCH",
            "ZRX",
            "KNC",
            "LRC",
            "REN",
            "ALCX",
            "ALPHA",
            "BADGER",
            "BNT",
            "CVX",
            "FXS",
            "GTC",
            "ILV",
            "INDEX",
            "INV",
            "LDO",
            "POOL",
            "RAI",
            "RARI",
            "RGT",
            "TORN",
            "TRIBE",
            "VISR",
            "FORTH",
            "AMP",
            "ANKR",
        }
        return symbol.upper() in defi_tokens

    def _create_complete_token_breakdown(self, all_tokens: list):
        """Create detailed breakdown for ALL tokens."""
        breakdown = {}
        total_value = sum(token.get("value_usd", 0) for token in all_tokens)

        for token in all_tokens:
            symbol = token.get("symbol", "UNKNOWN")
            value_usd = token.get("value_usd", 0)

            breakdown[symbol] = {
                "amount": token.get("amount", 0),
                "value_usd": value_usd,
                "percentage_of_portfolio": (
                    (value_usd / total_value * 100) if total_value > 0 else 0
                ),
                "category": self._categorize_token(symbol),
            }

        return breakdown

    def _create_complete_protocol_breakdown(self, all_protocols: list):
        """Create detailed breakdown for ALL protocols."""
        breakdown = {}
        total_value = sum(protocol.get("total_usd", 0) for protocol in all_protocols)

        for protocol in all_protocols:
            name = protocol.get("name", "UNKNOWN")
            value_usd = protocol.get("total_usd", 0)

            breakdown[name] = {
                "total_usd": value_usd,
                "percentage_of_protocol_exposure": (
                    (value_usd / total_value * 100) if total_value > 0 else 0
                ),
                "protocol_type": self._categorize_protocol(name),
            }

        return breakdown

    def _categorize_token(self, symbol: str) -> str:
        """Categorize a token by its symbol."""
        if self._is_stablecoin(symbol):
            return "stablecoin"
        elif self._is_major_crypto(symbol):
            return "major_crypto"
        elif self._is_defi_token(symbol):
            return "defi_token"
        else:
            return "other"

    def _categorize_protocol(self, name: str) -> str:
        """Categorize a protocol by its name."""
        name_lower = name.lower()

        if any(
            dex in name_lower
            for dex in ["uniswap", "sushiswap", "1inch", "curve", "balancer", "pancake"]
        ):
            return "dex"
        elif any(lending in name_lower for lending in ["aave", "compound", "maker", "liquity"]):
            return "lending"
        elif any(
            yield_term in name_lower for yield_term in ["yearn", "harvest", "convex", "pickle"]
        ):
            return "yield_farming"
        elif any(staking in name_lower for staking in ["lido", "rocket", "stakewise"]):
            return "staking"
        else:
            return "other"

    async def fetch_multiple_addresses(
        self, addresses: List[str], batch_name: Optional[str] = None
    ):
        """Fetch data for multiple addresses and create combined export."""
        print(f"üöÄ Fetching data for {len(addresses)} addresses...")

        all_exports = []
        successful_exports = 0

        for i, address in enumerate(addresses, 1):
            print(f"\nüìç Processing address {i}/{len(addresses)}: {address[:8]}...")

            export_data, filepath = await self.fetch_and_export_address(address)
            if export_data:
                all_exports.append(export_data)
                successful_exports += 1

            # Small delay between requests to be respectful
            if i < len(addresses):
                await asyncio.sleep(2)

        # Create combined export
        if all_exports:
            combined_data = self._create_combined_export(all_exports, batch_name)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            combined_filename = f"combined_eth_exposure_{batch_name or 'batch'}_{timestamp}.json"
            combined_filepath = self.output_dir / combined_filename

            with open(combined_filepath, "w") as f:
                json.dump(combined_data, f, indent=2, default=str)

            print(f"\nüíæ Combined data exported to: {combined_filepath}")
            print(f"üìà Combined Summary: {successful_exports}/{len(addresses)} addresses processed")

            return combined_data, combined_filepath

        return None, None

    def _create_combined_export(self, all_exports: List[Dict[str, Any]], batch_name: Optional[str]):
        """Create combined export from multiple address exports."""

        # Calculate total ETH exposure by analyzing tokens on-the-fly
        total_eth_exposure = 0.0
        addresses_with_eth = []

        for export in all_exports:
            eth_exposure_value = 0.0
            for token in export.get("tokens", []):
                if token.get("category") in ["eth_exposure", "eth_staking"]:
                    eth_exposure_value += token.get("usd_value", 0)

            total_eth_exposure += eth_exposure_value
            if eth_exposure_value > 0:
                addresses_with_eth.append(export["address"])

        combined_data = {
            "metadata": {
                "batch_name": batch_name or "unnamed_batch",
                "timestamp": datetime.now().isoformat(),
                "total_addresses": len(all_exports),
                "scraper_version": "enhanced_debank_scraper_v1.0",
            },
            "combined_summary": {
                "total_portfolio_value_usd": sum(
                    export["total_usd_value"] for export in all_exports
                ),
                "total_eth_exposure_usd": total_eth_exposure,
                "total_tokens_across_addresses": sum(
                    len(export["tokens"]) for export in all_exports
                ),
                "total_protocols_across_addresses": sum(
                    len(export["protocols"]) for export in all_exports
                ),
            },
            "individual_addresses": all_exports,
            "port2_integration_summary": {
                "recommended_total_eth_exposure_usd": total_eth_exposure,
                "addresses_with_eth_exposure": addresses_with_eth,
            },
        }

        return combined_data


async def main():
    """Main function for command-line usage."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Fetch comprehensive ETH exposure data using proven live scraper"
    )
    parser.add_argument("addresses", nargs="+", help="Ethereum addresses to fetch data for")
    parser.add_argument("--batch-name", help="Name for batch processing")
    parser.add_argument(
        "--output-dir", default="exported_data", help="Output directory for JSON files"
    )

    args = parser.parse_args()

    fetcher = ETHExposureDataFetcher(output_dir=args.output_dir)

    if len(args.addresses) == 1:
        # Single address
        await fetcher.fetch_and_export_address(args.addresses[0])
    else:
        # Multiple addresses
        await fetcher.fetch_multiple_addresses(args.addresses, args.batch_name)


if __name__ == "__main__":
    asyncio.run(main())
